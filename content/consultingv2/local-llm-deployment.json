{
  "blocks": [
    {
      "finalBreadcrumb": "Local LLM Deployment",
      "_template": "breadcrumbs"
    },
    {
      "topLabel": {
        "labelText": ""
      },
      "heading": "Run open-source LLMs on your own infra. Zero data egress.",
      "isH1": false,
      "description": "Get a production-ready, OpenAI-compatible API for open-source models, running entirely inside your network. 100% private.\n",
      "featureColumns": {
        "twoColumns": true
      },
      "buttons": [
        {
          "buttonText": "Book a PoC scoping call",
          "leadCaptureFormOption": "bookingJotFormId",
          "colour": 0
        }
      ],
      "mediaConfiguration": {
        "imageSource": "/images/ssw-web/hero/local-llm-hero.jpg",
        "imageHeight": 752,
        "imageWidth": 1392
      },
      "_template": "imageTextBlock"
    },
    {
      "heading": "Trusted by",
      "logos": [
        {
          "logo": "",
          "altText": "Logo"
        }
      ],
      "_template": "logoCarousel"
    },
    {
      "isStacked": true,
      "heading": "",
      "isH1": false,
      "body": "",
      "cardStyle": 1,
      "cards": [
        {
          "guid": "pzx5dv",
          "image": "/images/ssw-web/hero/local-llm.jpg",
          "altText": "Lorem Ipsum",
          "icon": "BiSolidServer",
          "heading": "Run on Your Infrastructure",
          "description": "Deploy to any VPC, private cloud, or bare-metal server. Guarantees zero data ever leaves your network, satisfying the strictest compliance and security requirements.",
          "embeddedButton": {
            "buttonText": ""
          }
        },
        {
          "guid": "07ihrh",
          "image": "/images/ssw-web/blog/openai-api.jpg",
          "altText": "Lorem Ipsum",
          "icon": "info",
          "heading": "Get an OpenAI-Compatible API",
          "description": "Your developers can use their existing tools by simply changing the API endpoint. This means zero learning curve and faster application development.",
          "embeddedButton": {
            "buttonText": ""
          }
        },
        {
          "guid": "xnidab",
          "image": "/images/ssw-web/blog/one-click-deploy.jpg",
          "altText": "Lorem Ipsum",
          "icon": "info",
          "heading": "Manage Models with One Click",
          "description": "Deploy, update, and scale optimized open-source models without MLOps expertise. Go from a model on Hugging Face to a production endpoint in minutes.",
          "embeddedButton": {
            "buttonText": ""
          }
        }
      ],
      "_template": "cardCarousel"
    },
    {
      "topLabel": {
        "labelText": "Case Study"
      },
      "heading": "How FinSecure Capital Deployed a Private, Open-Source LLM for Document Analysis in 48 Hours",
      "isH1": false,
      "description": "They needed to run LLMs on PII with zero data egress. A DIY build was soaking engineering time with no timeline. We installed an on-prem gateway, tuned open-source models, and proved lower latency and cost.\n",
      "featureColumns": {
        "twoColumns": false,
        "features": [
          {
            "heading": "The Challenge",
            "description": "Process KYC and contract docs in-house. No data may leave the perimeter. Public APIs were slow and expensive. The internal project drifted without clear SLOs."
          },
          {
            "heading": "The Outcome",
            "description": "Live in 48 hours. p95 latency 310 ms (↓~65%). Unit cost $0.11 / 1k tokens (↓~80%). Zero egress verified via firewall + Kubernetes NetworkPolicy tests."
          }
        ]
      },
      "buttons": [
        {
          "buttonText": "Read the Full Case Study",
          "colour": 0
        },
        {
          "buttonText": "Book a 30-min PoC",
          "colour": 1
        }
      ],
      "mediaConfiguration": {
        "imageSource": "/images/ssw-web/hero/case_study_local-llm.jpg",
        "imageHeight": 768,
        "imageWidth": 1408
      },
      "_template": "imageTextBlock"
    },
    {
      "isStacked": true,
      "heading": "",
      "isH1": false,
      "body": "",
      "cardStyle": 0,
      "cards": [
        {
          "guid": "e4a7x7",
          "altText": "Lorem Ipsum",
          "icon": "BiCrosshair",
          "heading": "100% Air-Gap Ready",
          "description": "",
          "embeddedButton": {
            "buttonText": ""
          }
        },
        {
          "guid": "2jlc1p",
          "altText": "Lorem Ipsum",
          "icon": "BiSolidLock",
          "heading": "SOC 2 / HIPAA Compliant",
          "description": "",
          "embeddedButton": {
            "buttonText": ""
          }
        },
        {
          "guid": "pwvxts",
          "altText": "Lorem Ipsum",
          "icon": "BiSolidTimer",
          "heading": "Deploys in < 1 Hour",
          "description": "",
          "embeddedButton": {
            "buttonText": ""
          }
        }
      ],
      "_template": "cardCarousel"
    },
    {
      "heading": "FAQ",
      "body": "Lorem ipsum dolor sit amet, consectetur adipiscing elit.",
      "accordionItems": [
        {
          "label": "How do you prove zero data egress?",
          "content": "Default-deny firewall + Kubernetes NetworkPolicy, scripted egress probes (hourly), and signed logs. We include the egress test pack and data-flow diagram for audits.\n"
        },
        {
          "label": "Do we need GPUs?",
          "content": "Recommended for throughput and p95. Typical start: 4× L40S (or A100/H100 equivalents). CPU-only is fine for light loads or batch jobs; we share a sizing guide.\n"
        },
        {
          "label": "Will our apps need changes?",
          "content": "Minimal. We expose an OpenAI-compatible endpoint, so existing clients usually point to a new base URL. Auth and rate limits are configured in the gateway.\n"
        }
      ],
      "_template": "accordionBlock"
    }
  ]
}